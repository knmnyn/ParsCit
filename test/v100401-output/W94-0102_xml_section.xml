<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="100401">
<algorithm name="SectLabel" version="100410">
<variant no="0" confidence="0.000003">
<sectionHeader confidence="0.927021333333333" genericHeader="abstract">
AMALGAM:
Automatic Mapping Among
Lexico-Grammatical Annotation Models
</sectionHeader>
<author confidence="0.987806">
Eric Atwell, John Hughes, and Clive Souter
</author>
<affiliation confidence="0.966803">
Centre for Computer Analysis of Language And Speech
School of Computer Studies, Leeds University, Leeds LS2 9JT, UK
</affiliation>
<email confidence="0.788669">
ericOscs.leeds.ac.uk johnOscs.leeds.ac.uk csOscs.leeds.ac.uk
</email>
<sectionHeader confidence="0.993885" genericHeader="method">
Abstract Introduction
</sectionHeader>
<bodyText confidence="0.999283833333333">
Several Corpus Linguistics research groups have gone
beyond collation of &apos;raw&apos; text, to syntactic annotation
of the text. However, linguists developing these lin-
guistic resources have used quite different wordtagging
and parse-tree labelling schemes in each of these anno-
tated corpora. This restricts the accessibility of each
corpus, making it impossible for speech and handwrit-
ing researchers to collate them into a single very large
training set. This is particularly problematic as there
is evidence that one of these parsed corpora on its own
is too small for a general statistical model of grammat-
ical structure, but the combined size of all the above
annotated corpora should deliver a much more reliable
model.
We are developing a set of mapping algorithms to
map between the main tagsets and phrase structure
grammar schemes used in the above corpora. We plan
to develop a Multi-tagged Corpus and a MultiTreebank,
a single text-set annotated with all the above tagging
and parsing schemes. The text-set is the Spoken En-
glish Corpus: this is a half-way house between formal
written text and colloquial conversational speech. How-
ever, the main deliverable to the computational linguis-
tics research community is not the SEC-based Multi-
Treebank, but the mapping suite used to produce it
this can be used to combine currently-incompatible
syntactic training sets into a large unified multicorpus.
Our architecture combines standard statistical language
modelling and a rule-base derived from linguists&apos; anal-
yses of tagset-mappings, in a novel yet intuitive way.
Our development of the mapping algorithms aims to
distinguish notational from substantive differences in
the annotation schemes, and we will be able to evalu-
ate tagging schemes in terms of how well they fit stan-
dard statistical language models such as n-pos (Markov)
models. 1
</bodyText>
<footnote confidence="0.8549154">
&apos;This research began with grants from the UK Science
and Engineering Research Council (SERC) and the Univer-
sities Funding Council&apos;s Knowledge Based Systems Initia-
tive (UFC KBSI), and is now funded by the UK Engineer-
ing and Physical Sciences Research Council (EPSRC) and
</footnote>
<bodyText confidence="0.99921754054054">
Several research projects around the world are building
grammatically analysed corpora; that is, collections of
text annotated with part-of-speech wordtags and syn-
tax trees. Tagged and parsed English corpora (Bank of
English [54]; BNC [44], [22]; Brown [24]; ICE [12], [28],
[64]; Lancaster-IBM [26], [22]; LOB [1], [3], [38], [42];
London-Lund [62]; Nijmegen [12]; PoW [23], [55], [57];
SEC [63]; TOSCA [46], [31], [12]; UPenn [53], [45]; etc)
are used, among other things, as authoritative exail !pies
by researchers in English Language Teaching and &apos;Lexi-
cography (e.g. [44]), and as training data for statistical
syntactic constraint models to improve recognition ac-
curacy in speech and handwriting recognisers (e.g. [37],
[10]).
However, projects have used quite different wordtag-
ging and parsing schemes. In contrast to the Speech
research community, which has reached broad agree-
ment on an uncontentious set of labelling conventions
for phonetic/phonemic analysis, there is no general con-
sensus in the international Natural Language research
community on analogous conventions for grammatical
analysis. Developers of corpora adhere to a variety of
competing models or theories of grammar and parsing,
with the effect of restricting the accessibility of their
respective corpora, and the potential for collation into
a single fully parsed corpus.
In view of this heterogeneity, we have begun to in-
vestigate and develop methods of automatically map-
ping between the annotation schemes of the most widely
known corpora, thus assessing their differences and im-
proving the reusability of the corpora. Annotating a
single corpus with the different schemes allows for Coln-
parisons, and will provide a rich test-bed for automatic
parsers.
The most widely known tagged corpora for English
are: the Lancaster-Oslo/Bergen (LOB) Corpus; the
Brown Corpus; and the London-Lund Corpus. In addi-
</bodyText>
<footnote confidence="0.998282">
the Higher Education Funding Councils&apos; New Technologies
Initiative (HEFCs&apos; NTI); we gratefully acknowledge their
financial support. We are also grateful to the Corpus Lin-
guistics research teams who have generously provided back-
ground information on their tagging and parsing schemes.
</footnote>
<page confidence="0.706099">
1 1
</page>
<bodyText confidence="0.996248310810811">
11011, the International Corpus of English (ICE) should
In&apos; included as its tagset has now been published [28].
Parsed corpora for English include: the Lancaster-IBM
•I&apos;reel) all k; the Lancaster-IBM Spoken English Corpus
(SEC!) &apos;Preebank; the Lancaster-Leeds Treebank; the
Polytechnic of Wales (POW) Corpus; the Nijmegen
Corpus; the TOSCA Corpus;; and the University of
Pennsylvania (UPenn) Treebank. We plan to include
the parsed ICE-GB (Great Britain component of ICE)
and the BNC (British National Corpus) in the project
when they become available.
As a development and testing resource, we are us-
ing the text of the Lancaster-IBM Spoken English Cor-
pus (SEC). The SEC is a collection of recordings of ra-
dio broadcasts with accompanying annotated transcrip-
tions, collected by Lancaster University and IBM UK
as a. general research resource. The SEC is available
from the International Computer Archive of Modern
English (ICAME) based at the Norwegian Computing
Centre for the Humanities (in Bergen, Norway). The
corpus exists in several forms and annotations: the digi-
tised acoustic waveform; the graphemic transcription
annotated with prosodic markings; and a part-of-speech
analysis (using the LOB Corpus tagset). Skeletal pars-
ing has been added to create the SEC Treebank, and
this forms a subset of the Lancaster-IBM Treebank.
(;erry Knowles (Lancaster) and Peter Roach (Leeds)
are collaborating in an ESRC-funded project to set up
a time-aligned database of recorded speech, accompa-
nied by phonetic and graphemic transcriptions. Our
proposal will produce, as a side-effect, several alterna-
tive tagged and parsed versions of the SEC which will
be made available to the SEC database project collab-
orators. It will also be able to act as a test-bed for the
comparison and evaluation of parsing schemes.
Objectives of the project
The main objectives are as follows
To design and implement algorithms for mapping be-
ween corpus annotation schemes; for both wordtag sets
and phrase structure grammar schemes.
To empirically evaluate the accuracy and shortcom-
ings of the developed mapping algorithms, by applying
them n to the tagged SEC and the SEC Tmebank. The
old come of this evaluation will be to highlight the no-
;Itiolial and substantive differences between the alter-
native tagging and parsing schemes.
build a Multi-Tagged Corpus, by enhancing the
Spoken English Corpus with different wordtagging
schemes.
To build a Multi-Treebank, by enhancing the Spoken
English Corpus with grammatical analyses according to
several alternative grammatical theories.
To investigate the use of the Multi-Treebank as a
1),•11chmark for grammars and parsers.
Initially, we considered adopting the Interlingua ap-
proach&apos; to mapping, as used in Machine Translation
projects such as EUROTRA. This would require us
to develop tagset mappings between the LOB Corpus
(our primary tagset Interlingua) and each of the &apos;ma-
jor&apos; tagged corpora: BROWN, ICE, Lancaster-IBM,
and UPenn. Next full grammar mappings would be
developed between the Lancaster-IBM Treebank (our
primary parsing scheme Interlingua) and each of: the
UPenn Treebank and the Lancaster-Leeds Treebank.
The ICE and BNC tagsets and parsing schemes could
be included when they become available. Mapping be-
tween tagsets will involve relabelling of words, whereas
mapping between grammar schemes also involves struc-
tural manipulation. These treebanks have been chosen
for their skeletal parsing schemes, which are of rela-
tively similar structure apart from a small number of
systematic differences.
We have chosen the SEC as a &apos;core&apos; text for this
project, because
</bodyText>
<listItem confidence="0.996750272727273">
1. the tagged SEC uses the same tagset as the LOB
Corpus (widely considered to be the UK standard
and our proposed primary tagset);
2. the parsed SEC uses the same grammatical scheme as
the Lancaster-IBM Treebank (our proposed primary
parsing scheme);
3. these are the annotation schemes which we have most
prior experience of;
4. the text material, BBC radio broadcasts, are a neu-
tral compromise between written and conversational
spoken English genres.
</listItem>
<bodyText confidence="0.999740793103448">
Our aim is to develop bidirectional mappings for
the above tagsets and grammar schemes, although we
appreciate that for mapping from simple to delicate
schemes this will not be possible, and that mappings
will be imperfect. As mapping algorithms are devel-
oped and tested, and whilst building the Multi-Tagged
Corpus and Multi-Treebank, we will compile &amp;quot;hand-
books&amp;quot; of common errors (i.e. mismatches) and their
corrections. These will help future users of the devel-
oped mapping algorithms to straightforwardly post-edit
their mapped corpora and treebanks, thus maximising
resource reusability. To map between two tagsets other
than LOB, two mappings will be necessary (via the
primary tagset, our &amp;quot;interlingua&amp;quot; representation); simi-
larly for non-terminal grammar schemes. We appreciate
the danger of propogating incorrect mappings.
If there is sufficient time, we hope to go on to in-
vestigate mapping algorithms for other (more detailed)
grammar schemes; for example the parsed POW Cor-
pus (Systemic Functional Grammar), and the parsed
Nijmegen Corpus (Extended Affix Grammar). The
non-corpus-based Generalised Phrase Structure Gram-
mar (GPSG) (as used in the Alvey Natural Language
Toolkit ANLT) should also be included. Mapping from
these to the Lancaster-IBM Treebank grammar scheme
would only be uni-directional i.e from a detailed to a
skeletal analysis.
The Multi-Treebank will be produced by applying
the final version of each grammar scheme mapping al-
</bodyText>
<page confidence="0.998795">
12
</page>
<bodyText confidence="0.999897">
gorithrn to the SEC Treebank. Similarly, for the Multi-
Tagged Corpus, the final version of each tagset mapping
algorithm will be applied to the tagged SEC. The re-
sulting annotations will then be intensively proofread
and post-edited. This will require consultations with
authorities in each of the tagsets and grammar schemes
involved.
</bodyText>
<subsectionHeader confidence="0.89855">
Progress to date
</subsectionHeader>
<bodyText confidence="0.996013846153846">
We envisage three main stages to the project: imple-
mentation of algorithms for mapping between tagsets;
implementation of algorithms for mapping between
phrase structure grammatical analysis schemes; and
investigating applications of the mapping programs,
multi-tagged corpus, and multi-treebank.
We are currently in the first of these. Mapping algo-
rithms are being designed and implemented between the
LOB Corpus tagset and each of: the tagged BROWN
Corpus, the tagged ICE, the Lancaster-IBM &apos;fl.eebank,
the UPenn Tagset (and the BNC tagset will be added
when published). Each tagset is being considered in
turn:
</bodyText>
<listItem confidence="0.982251142857143">
1. Analysis of the notational and substantive differences
between the LOB tagset and the &apos;current&apos; tagset.
2. Design and implementation of a mapping algorithm
(two-way, where possible).
3. Evaluate success of algorithm by applying it to the
tagged SEC; incrementally improve in light of com-
mon errors and linguistic intuition.
</listItem>
<bodyText confidence="0.990081263157895">
A side-effect of this phase is the production of a
Multi-Tagged Corpus: the SEC text annotated with
each tagset.
A standard format for tagged and parsed
corpora
As well as using different tagsets and parsing schemes,
different annotated corpora come in a range of different
formats see [57], [59], [60]. A non-trivial first step in
merging tagged and parsed corpora is to decide on a
unitary standardised format. Although the Text En-
coding Initiaitive (TEI) [61], [18] offers general guide-
lines for text formatting standards, and some corpora
(including BNC, ICE) aim to be &amp;quot;TEI-conformant&amp;quot;, in
practice it seems almost as hard for Corpus linguists
to agree to accept a single annotation format as it is
to agree on a single annotation scheme. Our mapping
software will use a standardised internal format for tag-
gings and parse-trees, but will have to be able to accept
input and produce output in a range of existing formats.
</bodyText>
<subsectionHeader confidence="0.905896">
Hand-crafting a detailed mapping
</subsectionHeader>
<bodyText confidence="0.999975484848485">
One approach to obtaining a mapping between two
tagsets is to use expert linguistic knowledge in iden-
tifying the relationship between particular tags, and is
exemplified in, for example, [58]. In this work, Souter
drew up a mapping between the parts of speech used in
the CELEX database [17], (which were themselves de-
rived largely from those in LDOCE [51]), and the sys-
temic functional grammar (SFG) used to hand parse
the Polytechnic of Wales corpus [23], [55].
The aim was to provide a large lexicon to support
SFG-based parsing programs. The original CELEX lex-
icon, which contained some 80,000 English wordforms.
was transformed into a lexicon with SFG tags, using a
semi-automatic mapping program, written in the AWK
programming language. The resulting lexicon was then
compatible with a large corpus-based systemic gram-
mar consisting of over 4,000 phrase-structure rules [56].
Together they can then support relatively robust prob-
abilistic parsing programs.
The problems encountered in trying to specify suck
a mapping result from disparity in the level of delicacy
in the two tagging schemes. Mapping from a coarseto
fine-grained grammar must be achieved manually, use
subcategorisation information contained in the lexi coil,
contextual information, or exception lists. Souter&apos;s pro-
gram contained simple one-to-one mappings, many-to-
one mappings, and one-to-many mappings supported
by exception lists and subcategorisation information.
In his work, contextual information could not be used
to support the mapping because the source material was
a lexicon and not a tagged corpus. A small part of the
mapping code (used to map between pronoun labels) is
shown in Figure 1.
</bodyText>
<equation confidence="0.8534288">
else if (category == &amp;quot;PROW&amp;quot;) # pronouns
{
if (\$8 == &amp;quot;Y&amp;quot;) printf(&amp;quot;HWH)(&amp;quot;) # WH-pronouns
else if ((\$1 == &amp;quot;no-one&amp;quot;)II\
(\81 == &amp;quot;nobody&amp;quot;)II\
(\$1 == &amp;quot;nothing&amp;quot;)1I\
(\$1 == &amp;quot;noone&amp;quot;)II\
(\$1 == &amp;quot;none&amp;quot;))
printf(&amp;quot;HPN)(&amp;quot;) # negative pronouns
else printf(&amp;quot;HP)(&amp;quot;) # other pronouns
</equation>
<figureCaption confidence="0.97623">
Figure 1: Fragment of an AWK mapping
from CELEX to SFG tagsets
</figureCaption>
<bodyText confidence="0.999867444444444">
Here, the coarse-grained CELEX tag PRON (pro-
noun) is mapped to three SFG tags, HWH, HPN and
HP. The default mapping is to HP (pronominal head of
the nominal group), but if the CELEX lexicon contains
subcategorisation information in the form of a Y in col-
umn 8, then we can assign the label for wh-Pronoun
head (HWH). An exception list is used to map to the
third SFG pronoun label (HPN), for negative pronoun
heads.
</bodyText>
<subsectionHeader confidence="0.812799">
Incremental refinement through feedback
</subsectionHeader>
<bodyText confidence="0.999507666666667">
Earlier work at Leeds [32] explored ways that a prob-
abilistic grammar may be improved with positive feed-
back from a human user; this has direct iniplications
</bodyText>
<page confidence="0.999273">
13
</page>
<bodyText confidence="0.998521461538461">
for how to improve the mappings incrementally. As the
mapped annotations are to be hand-corrected by ex-
perts this provides positive feedback. Rather than tag .
the core text completely using the best derived mapping
a better idea would be to do it in sections and then have
he expert correct the errors in each section in turn. Af-
ter each section is complete the mapping rules will be
updated to incorporate the new information. Hopefully
this will enable future sections to be mapped more ac-
curately. This method is similar to that used by the
N ijmegen corpus. parsing group, [47]
Problems with the int erlingua-based
approach
The interlingua idea seems sound for several reasons.
Amongst these is the saving made in required map-
pings. For instance, five tagging schemes would require
twenty mappings if each pair is mapped directly in both
directions. However only eight mappings are required
if one of the tagging schemes acts as an interlingua.
This saving becomes greater as more tagging schemes
are considered. The interlingua also helps the map-
pings attain a level of consistency as the interlingua
is the basis of all possible mappings from one tagging
scheme to another. However, the interlingua may cause
problems in the instances where it is coarse-grained rel-
ative to other tagging schemes. For instance, the LOB
tagset has no notion of verb transitivity whereas the
ICE tagset does. If a mapping is being made between
two tagging schemes both of which incorporate the con-
cept of transitivity then a tag may be wrongly allocated
as the sense of transitivity is lost via the LOB tagset
interlingua.
One problem with the work plan is the strong em-
phasis on this problem of imperfect mappings due to
course-grained parts of the interlingua. It may turn out
after experimentation that the contextual information
of the surrounding tags and words make up for this.
The sentence, S, the interlingua tags, a, and the other
tagging scheme&apos;s tags, b, can be represented as follows:
</bodyText>
<table confidence="0.970089571428571">
Sentence Tagging 1 Tagging 2
SI al 61
S2 a2 62 b3
S3 a3 •
• a n _ 2 a n - 1 on- 2
• n bn-1 bn
Sn - 2 Sn - 1 Sn
</table>
<bodyText confidence="0.994666631578947">
Using a window of the closest four neighbours, say,
the tag a; when presented with a difficult tag, k, has
the additional context information of Si-2, S1-1, Si+1,
s,&amp;quot;, a, -9, aj-- , (441 and ni+2 to work on. Previous
research 011(1in-hug [4], [5], [33], [34], [35], [36]) has indi-
cated I hat there is a high degree of useful contextual in-
format ion implied by the surrounding items. This con-
textual information can be used with clustering tech-
niques to classify words. These techniques could be
applied to the tagging scheme with little modification.
The classifications could then be examined to see which
types of tag are difficult to group. Tags which are dif-
ficult to cluster may be useful in identifying problem
areas early. As an example, Figure 2 shows a clustering
dendogram for the LOB Corpus tagset.
One possible problem might be: given the set of
words in (S1 ...Sn) and the interlingua tags (al • • • an)
how are the other tagging scheme&apos;s tags (b1 bn) de-
rived? Obviously, the tagging scheme itself can be used
to map directly the words (S1 Sn) onto the tags
(b1 bn) without knowledge of the interlingua tags
(al ...an). Also, mappings could be made solely be-
tween the interlingua tags (al ... an) and the other tags
(b1 Lys). This could be done by having an expert tag
a section of the &apos;core text&apos; with both the interlingua and
the other tagging scheme. Probabilisitic rules could be
derived indicating how the tags match up. These rules
would be strengthened if the context of the surrounding
tags was incorporated.
When the two pieces of information are combined it
is hoped that a more accurate mapping can be achieved.
This can be done by mapping directly from the word
plus tag to the new tag. For instance;
+ a 1-4 bi.
However, rules could grow very large even when reg-
ularities are used to reduce their number.
Alternatively, a mapping could be made for Si 1-+ bit
according to the standard annotation rules for the non-
interlingua tagging scheme; and a mapping could be
done for ai ka according to the procedure outlined
above. These mappings produce two potential tags in-
dependently. One algorithm might always accept b11
when bil = biz. When 141 0 142 a decision needs to
be made as to which, if any, of the tags should be cho-
sen. Brill [14] developed a clever and highly accurate
tagging scheme which could have implications for this
problem. He tagged every occurrence of a word with its
most probable tag if there was more than one choice. A
second pass of the corpus would update the tags accord-
ing to a set of automatically acquired rules. A similar
idea could be utilised to choose between the tags. Per-
haps the most probable tag would always be selected
on the first pass but we would allow that decision to be
altered on a second pass according to rules derived from
earlier sections of the corpus that had been tagged and
checked by the expert linguist. This, then, is another
example of incremental learning.
</bodyText>
<subsectionHeader confidence="0.8998175">
Combining Symbolic and Statistical
Approaches to Language
</subsectionHeader>
<bodyText confidence="0.99983625">
Our research is particularly relevant to this work-
shop, as it is clear we will have to combine rule-
based symbol-mapping knowledge with statistical dis-
ambiguation models. We envisage that the bulk of a
</bodyText>
<page confidence="0.999215">
14
</page>
<bodyText confidence="0.971691333333333">
mapping can be done using simple one-to-one symbol
replacement rules; but some rules will map one source
symbol onto a set of more than one target symbol. A
</bodyText>
<figure confidence="0.67921175">
a statistical part-of-speech tagger along the lines of the
WWI
IN
VIDIR CLAWS tagger used on LOB [42], [3], [25] can then be
VI
used to select between the reduced candidate set, using a
IDC
PP! statistical context model; probably a 1st-order Markov
irtr
WIN
&amp;quot; or Bi-Pos model is most appropriate as this is the sim-
nu
PIUS plest &apos;standard&apos; statistical language model and is widely
MAE
PIT
MI
PP3A used and understood, see for example [2], [48], [7], [37],
WEI [9], [49].
HT
HVN
BED
Ill We can arrive at such a model of source-to-target
=CC
WIL
TIVD mapping by &apos;working backwards&apos;: first run a CLAWS-
Ira
I= style Markovian target-tagset tagger over the text, ig-
HVG
,La 22D
TOMD
KNOT
70&apos;
</figure>
<bodyText confidence="0.999240666666667">
noring the source tags; proofread the output to note
where this makes mistakes (assigns incorrect target
tags); and then devise source-to-target tag mapping,
</bodyText>
<equation confidence="0.762050608695652">
VP
zr rules only for these cases. We are aware from our own
rari
1 2.,
CDCD
NI
APO initial attempts at deivising tag-mappings that this re-
Ma
ME quires a high level of specialist linguistic knowledge, of
both source and target tagset; this &amp;quot;symbolic patching
NP
CD3
NNW of the statistical model&amp;quot; approach minimises the `lin-
i___=r sat guistic expertise&apos; we need to capture (and first develop!)
NFU
P1503 &amp;quot;patches&amp;quot; to fix the flaws in the statistical model as and
PPIO
PITCH
WPO when we spot them patching up a program as the bugs
DIE
Ar
seep out. However, we prefer to view this as a princi-
CC
</equation>
<bodyText confidence="0.982734">
pled, well-founded approach to combining symbolic and
</bodyText>
<sectionHeader confidence="0.543271" genericHeader="method">
WPCS,
</sectionHeader>
<bodyText confidence="0.906145">
statistical models, minimising the &apos;overlap&apos; by ensuring
</bodyText>
<equation confidence="0.980400166666667">
77
that each has a separate useful contribution to make to
Nrr
I NI% the overall mapping task.
NC
WPA
</equation>
<bodyText confidence="0.9992275">
We envisage combining a CLAWS-style tagger mod-
ule for each of the target tagsets into a single Multi-
tagger program. This accepts as input a stream of
words annotated with tag(s) from one (or more) of the
source tagsets; to output is a stream of words plus tags
from ALL target tagsets. This model allows for litchi-
</bodyText>
<listItem confidence="0.762579">
AT sion of mapping rules both direct from source to target
• All
</listItem>
<bodyText confidence="0.803743">
Fps tagset, and via an interlingua (a backup default to try
</bodyText>
<subsectionHeader confidence="0.913381">
D11
</subsectionHeader>
<bodyText confidence="0.984785">
if there are no direct mapping rules).
</bodyText>
<figure confidence="0.910867416666666">
cD
wDr
NIS
I iWr
RI
Software Engineering principles in advocating symbolic
to devise symbolic mapping rules. We have learnt of
&amp;RV
IN
WIT corpus-tagset mapping work by a number of other re-
NHL
gvv,
generally such research in the past has been merely a
searchers (including [13], [30], [20] [39] [41], [52]), but
IT
Exa
DDC means to an end (to create a re-tagged Corpus), so
NW
Va;
the full mapping algorithms have not been formalised
PN
or published; but if all we need is a limited nuber of&apos;
VIM
AUL mapping-rules to &amp;quot;patch&amp;quot; the Markov model then we
rirpoiDIS may be able to glean sufficient details from informal
notes etc. It may appear that we are promoting bad
AD/
CD
Future Work
NAN
WEES
WPM
OD
NNTHI
NM
NIP
</figure>
<figureCaption confidence="0.999731">
Figure 2: A Clustering of LOB Tags
</figureCaption>
<bodyText confidence="0.9991236">
The remainder of the project will be devoted to the
two other phases of the plan listed earlier, mapping be-
tween phrase-structure parsing schemes, and investigat-
ing applications of the multi-tagged corpus and multi-
treebank.
</bodyText>
<page confidence="0.997277">
15
</page>
<subsectionHeader confidence="0.961785">
Implementation of Algorithms For
Mapping Between Grammar Schemes
</subsectionHeader>
<bodyText confidence="0.9966488">
Initially mapping algorithms will be designed and im-
plemented between the Lancaster-IBM Treebank gram-
mar scheme, and each of the UPenn Treebank and the
Lancaster-Leeds Treebank. Each grammar scheme will
be considered in turn:
</bodyText>
<listItem confidence="0.9696723">
I. Analysis of the notational and substantive differences
between the Lancaster-IBM grammar scheme and the
&apos;current&apos; grammar scheme.
2. Manually parse a subset of the SEC according to the
current&apos; grammar scheme. This subset should be
sufficient to allow a prototype mapping algorithm to
be induced.
3. Apply mapping algorithm to the parsed SEC; incre-
mentally improve in light of common errors and lin-
guistic intuition.
</listItem>
<bodyText confidence="0.999977357142857">
Depending on how much time is available, mapping
algorithms for more detailed grammar schemes will be
investigated: parsed POW Corpus, parsed Nijmegen
Corpus, GPSG, and the BNC grammar scheme (when
published). A side-effect of this phase will be the pro-
duction of a Multi-Treebank; the SEC automatically
annotated with each grammar scheme.
The all-in-one Multi-tagger architecture outlined
above can be carried over to a Multi-parser. Instead
of a CLAWS-style Markovian tagger, for each target
parsing scheme a grammar and parser can be extracted
directly from the corresponding training Treebank. A
Context-Free Grammar can be elicited directly by ex-
tracting each non-terminal and its immediate-daughter-
sequence, to become the left-hand-side and right-hand-
side respectively of a context-free grammar rule [6]; fre-
quencies of constituents in the training treebank can be
used to make this a Probabilistic Context Free Gram-
mar [49], useable in a treebank-trained probabilistic
parser such as those in [2], [29], [9], [50]. Rather than
producing a single, fully correct parse-tree for each
input sentence, these probabilistic Treebank-trained
parser generally output an ordered list of possible parse-
trees, with a probability or weight attached to each.
As with the procedure for developing a partial tag-
[napping, we need only devise source-to-target parse-
tree-constituent mappings in cases where the target-
parser&apos;s &apos;best&apos; parsetree is not fully correct.
</bodyText>
<subsectionHeader confidence="0.97441">
Assessment of the Multi-Treebank as a
Benchmark for Grammars
</subsectionHeader>
<bodyText confidence="0.996099283333334">
&apos; l&apos;his requires analysis of the substantive differences be-
tween different parses of the SEC sentences; detailed
analysis of how many and which constructs differ in
the different language models. It may be possible to
divide the sentences in the SEC into two subsets: a
common core of &amp;quot;uncontentious&amp;quot; sentences which all or
most theories analyse in much the same way; and a
&amp;quot;troublesome&amp;quot; subset of sentences which linguists can
concentrate their debate on.
One possible criticism of a lot of work in Corpus
Linguistics, including the AMALGAM, proposed work-
plan, is that we restrict ourselves to variants of exist-
ing tagging and parsing schemes which are specifically
crafted for Corpus annotation, but which are quite dif-
ferent from grammar models being advocated and de-
veloped by non-Corpus-based theoretical linguists, such
as GPSG or HPSG (see e.g. [27]). Unfortunately, we
know of no English corpus parsed according to such
a feature-based unification-oriented formalism, so one
cannot readily be included in the AMALGAM project;
however, we would like to hear from theoretical linguists
who we could collaborate with in extending the multi-
parser to a unificational grammar formalism. It is not
clear that our multi-corpus will be a &apos;fair&apos; benchmark
for testing grammars and parsers from such widely-
differing theories; it will be interesting to see whether
the partition between &amp;quot;uncontentious&amp;quot; and &amp;quot;trouble-
some&amp;quot; sentences is also applicable in assessment of uni-
ficational grammars.
Another constraint of the AMALGAM project is that
we are not considering Corpus-based semantic tagging
schemes (e.g. [40], [22], [21]), only syntactic tagging
schemes. Again, it will be interesting to see whether
the syntactically &amp;quot;troublesome&amp;quot; sentences are also se-
mantically complex or anomalous; but this is a question
for another, follow-up, project.
Comparison of the Multi-Treebank with
other parsed corpora
We will compare the SEC data with other parsed texts
(LOB, UPenn, POW, Nijmegen, etc), to assess differ-
ences in the range and frequency distributions of gram-
matical constructs. The SEC consists of transcripts
of scripted (and probably rehearsed) radio broadcasts.
Some natural language researchers may feel that the
Spoken English dataset is thus inappropriate for their
work, since the grammars and parsers they are devel-
oping are designed for a different type of language,
for example, unrehearsed informal spoken dialogue as
found in the London-Lund Corpus and British Na-
tional Corpus spoken section, or more formal published
(written) text as found in the Brown and Lancaster-
Oslo/Bergen Corpora. It may be appropriate to aug-
ment the SEC dataset with additional material from
alternative sources. On the other hand, it may be that
the main differences are in vocabulary rather than syn-
tax, and that the coverage of the SEC, though not com-
plete or perfect, is adequate for most applications. We
will try to find empirical evidence for or against the ac-
ceptability of &apos;scripted&apos; Spoken English to the NL corn-
mun ity.
</bodyText>
<page confidence="0.997919">
16
</page>
<subsectionHeader confidence="0.69567">
Assessment of Multi-Treebank as a
Benchmark for Parsers
</subsectionHeader>
<bodyText confidence="0.9999858">
This will involve attempting to parse the SEC text with
other parsers, available from a variety of sources. To
avoid the need for intensive manual proofreading or
checking of results, a (semi-)automatic assessment pro-
cedure will be developed.
</bodyText>
<sectionHeader confidence="0.684965" genericHeader="conclusions">
Anticipated Results
</sectionHeader>
<bodyText confidence="0.9993135">
The tangible &apos;deliverables&apos; of use to the Speech and
Language research community include:
</bodyText>
<listItem confidence="0.999958222222222">
• Final implementations of algorithms for mapping be-
tween pairs of tagsets
• Final implementations of algorithms for mapping be-
tween pairs of Treebanks
• Handbooks of common errors and corrections for
post-editing
• The Multi-Tagged Corpus
• The MultiTreebank
• Reports on the above
</listItem>
<bodyText confidence="0.999954">
The mapping software, Multi-tagged Corpus and
MultiTreebank (along with postediting handbooks and
documentation) will be delivered to ICAME and Ox-
ford Text Archive for public distribution; they will
also be available for incorporation into the SEC Speech
Database. Reports on the findings of the three stages
of investigations will be made widely available to all in-
terested parties through SALT and ELSNET (UK and
European Networks of Excellence) and other channels
including conference presentations and journal papers.
</bodyText>
<subsectionHeader confidence="0.779923">
Applications
</subsectionHeader>
<bodyText confidence="0.99995521875">
The implemented mapping algorithms will be made
widely available to the UK and international speech
and language research community. They will allow re-
search groups who are using corpus-based training data
to make use of other corpora straightforwardly, without
substantial modifications. Any current and future users
of corpora will have a much expanded resource.
The Multi-Tagged Corpus and the Multi-Treebank
will be distributed, along with the main Spoken English
Corpus, through ICAME. They will also be available for
incorporation into the SEC Speech Database currently
being created by Gerry Knowles and Peter Roach, fur-
ther enhancing the SEC as a general research resource.
Both the Multi-Treebank and the Multi-Tagged cor-
pus will potentially be used by speech and language
technology groups for many research and teaching pur-
poses, including: training data for speech-recognisers,
optical text recognisers, word processor text-critiquing
systems, machine translation systems, natural language
interfaces, and NLP applications generally; and for pro-
viding examples for English Language Teaching (ELT)
grammar textbooks and training material. In addi-
tion, the Multi-Treebank may be used as a testbed and
benchmark for parsers (explored in the workplaii). It
would also be a rich resource for grammar-learning ex-
periments a research topic of growing interest (see e.g.
[8], [11], [16], [33]).
We envisage supplying the computational linguistics
research community with a valuable research resource,
and the ACL Workshop will be an invaluable opportu-
nity for us to survey potential customer requirements
and preferences!
</bodyText>
<sectionHeader confidence="0.941067" genericHeader="references">
References
</sectionHeader>
<listItem confidence="0.975668764705882">
[1] Eric Steven Atwell. 1982. LOB Corpus Mining
Project: Manual Post-edit Handbook. Departments
of Computer Studies and Linguistics, Lancaster Uni-
versity.
[2] Eric Atwell. 1983. Constituent Likelihood G rain-
mar. In Journal of the International Computer
Archive of Modern English (ICAME Journal), No. 7,
pages 34-66. Norwegian Computing Centre for the
Humanities, Bergen University
[3] Eric Steven Atwell, Geoffrey Leech and Roger Gar-
side 1984. Analysis of the LOB Corpus: progress arid
prospects in Jan Aarts and Willem Meijs (ed), Cor-
pus Linguistics: Proceedings of the ICAME 4th Inter-
national Conference on the Use of Computer Corpora
in English Language Research pp40-52, Amsterdam:
Rodopi.
[4] Eric Steven Atwell. 1987. A parsing expert system
which learns from corpus analysis. In Willem Meijs,
editor, Corpus Linguistics and Beyond: Proceedings
of the ICAME 7th International Conference, pages
227-235. Amsterdam, Rodopi.
[5] Eric Steven Atwell and Nikos Drakos. 1987. Pattern
Recognition Applied to the Acquisition of a Grain-
matical Classification System from Unrestricted En-
glish Text. In Bente Maegaard, editor, Proceedings of
the Third Conference of European Chapter of the .4s-
sociation for Computational Linguistics, New Jersey,
Association for Computational Linguistics.
[6] Eric Steven Atwell. 1988. Transforming a parsed
corpus into a corpus parser. In Merja Kyto, Ossi
Ihalainen, and Matti Risanen, editors, Corpus Lin-
guistics, Hard and Soft: Proceedings of the ICA MI
8th International Conference, pages 61-70. Amster-
dam, Rodopi.
</listItem>
<reference confidence="0.938962545454545">
[7] Eric Steven Atwell. 1988. Grammatical analysis of
english by statistical pattern recognition. In Josef
Kittler, editor, Pattern Recognition: Proceedings of
the 4th International Conference Cambridge, pages
626-635. Berlin, Springer-Verlag.
[8] Eric Steven Atwell. 1992. Overview of grammar
acquisition research. In Henry Thompson, editor,
Workshop on sublanguage grammar and tezicon ac-
quisition for speech and language: proceedings, pages
65-70. Human Communication Research Centre, Ed-
inburgh University.
</reference>
<page confidence="0.995109">
17
</page>
<reference confidence="0.999516425925927">
[9] Eric Steven Atwell. 1993. Corpus-based statistical
modelling of English grammar. In Clive Souter and
Eric Atwell, editors, Corpus-Based Computational
Linguistics, pages 195-214. Amsterdam, Rodopi.
[10] Eric Steven Atwell. 1993. Linguistic Constraints
for Large-Vocabulary Speech Recognition In Eric
Steven Atwell (ed), Knowledge at Work in Univer-
sities: Proceedings of the second annual conference
of the Higher Education Funding Councils&apos; Knowl-
edge Based Systems Initiative, pp26-32. Leeds, Leeds
lIniversity Press.
[11] Eric Steven Atwell, Simon Arnfield, George
Dernetriou, Stephen Hanlon, John Hughes, Uwe Jost,
Rob Pocock, Clive Souter, and Joerg Ueberla. 1993.
Multi-level disanibiguation grammar inferred from
English corpus, treebank and dictionary. In Proceed-
ings of the IEE Two One-Day Colloquia on Gram-
matical Inference : Theory, Applications and Alter-
natives, (Ref 1993/092). London, Institution of Elec-
trical Engineers (IEE).
[12] Honk Barkema. 1994. The TOSCA Analysis En-
vironment for ICE. Technical Report, Department
of Language and Speech, Katholieke Universiteit Ni-
jmegen, The Netherlands.
[1:1] Nancy Belmore. 1991. Tagging Brown with the
LOB tagging suite. In Journal of the International
Computer Archive of Modern English (ICAME Jour-
nal), No. 15, pages 63-86. Norwegian Computing
Centre for the Humanities, Bergen University.
[14] Eric Brill. 1991. A Simple Rule-Based Part of
Speech Tagger. Technical Report: Department of
Computer Science, University of Pennsylvania.
[15] Eric Brill and Mitchel Marcus. 1992. Tagging an
Unfamiliar Text with Minimal Human Supervision.
In Robert Goldman, editor, Working notes of the
A A Al Fall Symposium on Probabilistic Approaches
to Natural Language, AAAI Press.
[16] Eric Brill, David Magerman, Mitchell Marcus,
and Beatrice Santorini. 1992. Deducing Linguistic
Structure from the Statistics of Large Corpora. In
Carl Weir and Ralph Grishman, editors, Proceedings
of AAAI-92 Workshop Program: Statistically-Based
NLP Techniques San Jose, California.
[17] Gavin Burnage. 1990. CELEX - A Guide for Users.
N iiniegen: Centre for Lexical Information (CELEX).
[18] Lou Burnard. 1991. What is the TEI? In D. Green-
stein, editor, Modelling Historical Data. Goettingen:
Katharinen.
09] K. Church. 1992. Parts of Speech Tagging. Fifth
A initial CIJNY Conference on Human Science Pro-
[20] Aviv Cohen. 1994. personal communication.
[21] ( :isorge C. Demetriou and Eric Steven Atwell.
19111. Machin e- Learn able, Non-Compositional Se-
mantics for Domain Independent Speech or Text
Recognition to appear in Proceedings of 2nd Hellenic-
European Conference on Mathematics and Informat-
ics (HERMIS), Athens University of Economics and
Business.
[22] Elizabeth Eyes and Geoffrey Leech. 1993. Progress
in UCREL research: Improving corpus annotation
practices. In Jan Aarts, Pieter de Haan, and Nelleke
Oostdijk, editors, English Language Corpora: de-
sign, analysis and exploitation; Proceedings of the
13th ICAME conference, pages 123-144. Amsterdam:
Rodopi.
[23] Robin Fawcett and Michael Perkins. 1980. Child
Language Transcripts 6-12. (With a preface, in 4 vol-
umes). Department of Behavioural and Communica-
tion Studies, Polytechnic of Wales.
[24] W.N. Francis and H. Ktgera. 1979. Manual
of Information to Accompany a Standard Corpus of
Present-Day Edited American English, for use with
Digital Computers (Corrected and Revised edition).
Department of Linguistics, Brown University, Provi-
dence, Rhode Island.
[25] Roger Garside, Geoffrey Leech, and Geoffrey
Sampson (editors). 1987. The Computational Analy-
sis of English : A Corpus-Based Approach. Longman,
London and New York.
[26] Roger Garside, Geoffrey Leech and Tomas VAradi.
1990. Manual of Information for the Lancaster
Parsed Corpus. Technical Report, Department of
Linguistics and Modern English, University of Lan-
caster, UK.
[27] Gerald Gazdar and Chris Mellish. 1989. Natural
Language Processing in POP-11 : An Introduction
to Computational Linguistics. Addison Wesley.
[28] Sidney Greenbaum. 1993. The Tagset for the In-
ternational Corpus of English. In Clive Souter and
Eric Atwell (eds.) Corpus-based Computational Lin-
guistics Amsterdam: Rodopi.
[29] Robin Haigh, Geoffrey Sampson and Eric Atwell.
1988. Project APRIL a progress report on the Leeds
annealing parser project. In Proceedings of the 26th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 104-112. New Jersey,
Association for Computational Linguistics (ACL).
[30] Robin Haigh. 1993. personal communication.
[31] Hans van Halteren and Nelleke Oostdijk. 1993.
Towards a syntactic database: the TOSCA anal-
ysis system. In Jan Aarts, Pieter de Haan, and
Nelleke Oostdijk, editors, English Language Corpora:
design, analysis and exploitation; Proceedings of the
13th ICAME conference, pages 145-162. Amsterdam:
Rodopi.
[32] John Hughes. 1989. A Learning Interface to the
Realistic Annealing Parser. Technical Report: School
of Computer Studies, The University of Leeds.
</reference>
<page confidence="0.994148">
18
</page>
<reference confidence="0.99979479245283">
[33] John Hughes and Eric Steven Atwell. 1993. uto-
matically acquiring and evaluating a classification of
words In Proceedings of the IEE Two One-Day Col-
loquia on Grammatical Inference : Theory, Applica-
tions and Alternatives, (Ref 1993/092). London, In-
stitution of Electrical Engineers (IEE).
[34] John Hughes. 1994. Automatically Acquiring a
Classification of Words. PhD Thesis: School of Com-
puter Studies, The University of Leeds.
[35] John Hughes and Eric Steven Atwell. 1994. A
Methodical Approach to Word Class Formation Us-
ing Automatic Evaluation. In Lindsay Evett and
Tony Rose, editors, Proceedings of AISB workshop
on Computational Linguistics for Speech and Hand-
writing Recognition. Leeds University.
[36] John Hughes and Eric Steven Atwell. 1994. The
Automated Evaluation of Inferred Word Classifica-
tions. In Tony Cohn (ed), Proceedings of the nti4
European Conference on Artificial Intelligence, Am-
sterdam.
[37] F. Jelinek. 1990. Self-organised language modelling
for speech recognition. In Alex Waibel and Kai-Fu
Lee, editors, Readings in Speech Recognition, pages
450-506. Morgan Kaufmann.
[38] Stig Johansson, Eric Atwell, Roger Garside and
Geoffrey Leech. 1986. The Tagged LOB Corpus -
Users&apos; Manual. The Norwegian Centre for the Hu-
manities, Bergen.
[39] Stig Johansson. 1994. personal communication.
[40] Uwe Jost and Eric Steven Atwell. 1993. Deriving a
probabilistic grammar of semantic markers from un-
restricted English text In Proceedings of the IEE Two
One-Day Colloquia on Grammatical Inference : The-
ory, Applications and Alternatives, (Ref 1993/092).
London, Institution of Electrical Engineers (IEE).
[41] Judith Klavans. 1994. personal communication.
[42] Geoffrey Leech, Roger Garside and Eric Atwell.
1983. The automatic grammatical tagging of the
LOB Corpus. In Journal of the International Com-
puter Archive of Modern English (ICAME Journal),
No. 7, pages 13-33. Norwegian Computing Centre for
the Humanities, Bergen University.
[43] Geoffrey Leech and Roger Garside. 1991. Running
a grammar factory: The production of syntactically
analysed corpora or &amp;quot;treebanks&amp;quot;. In Stig Johansson
and Anna-Brita StenstrOm, editors, English Com-
puter Corpora: Selected Papers and Research Guide.
Berlin: Mouten de Gruyter.
[44] Geoffrey Leech. 1993. 100 Million Words of En-
glish: The British National Corpus (BNC) Project.
English Today.
[45] Mitch P. Marcus and Beatrice Santorini. 1992.
Building Very Large Natural Language Corpora: The
Penn Treebank. In N. Ostler, editor, Proceedings of
the 1992 Pisa Symposium on European Textual Cor-
pora.
[46] Nelleke Oostdijk. 1989. TOSCA Corpus Manual.
University of Nijmegen.
[47] Nelleke Oostdijk. 1991. Corpus linguistics and Ow
automatic analysis of English. Amsterdam: Rodopi.
[48] Marian Owen. 1987. Evaluating automatic gram-
matical tagging of text. In Newsletter of the Interna-
tional Computer Archive of Modern English (ICAME
NEWS), No. 11, pages 18-26. Norwegian Computing
Centre for the Humanities, Bergen University.
[49] Rob Pocock and Eric Atwell. 1993. Extracting sta-
tistical grammars from the Lancaster-IBM Spoken
English Corpus Treebank. Technical Report 93.29,
School of Computer Studies, Leeds University.
[50] Rob Pocock and Eric Atwell, 1993. Probabilis-
tic grammatical models for treebank-trained lattice
disambiguation. Technical Report 93.30, School of
Computer Studies, Leeds University.
[51] Paul Procter. 1978. Longman Dictionary of Con-
temporary English. London: Longman.
[52] Geoffrey Sampson. 1994. &amp;quot;personal communica-
tion&amp;quot;.
[53] Beatrice Santorini. 1990. Part-of-speech tagging
guidelines for the Penn treebank project. Technical
Report MS-CIS-90-47, Department of Computer and
Information Science, University of Pennsylvania.
[54] John Sinclair. 1987. &apos;Looking Up: An Account of
the COB UILD Project in Lexical Computing. Collins,
Glasgow.
[55] Clive Souter. 1989. A short handbook to the l&apos;oly-
technic of Wales Corpus. Bergen: Norwegian Com-
puting Centre for the Humanities, Bergen University.
[56] Clive Souter. 1990. Systemic functional grammars
and corpora. In J. Aarts and W. Meijs, editors, The-
ory and Practice in Corpus Linguistics, pages 179-
211. Amsterdam: Rodopi.
[57] Clive Souter and Eric Steven Atwell. 1992. A
richly annotated corpus for probabilistic parsing. In
Carl Weir and Ralph Grishman, editors, Proceedings
of AAAI workshop on Statistically-Based NL P Tech-
niques, San Jose, CA, pages 28-38.
[58] Clive Souter. 1993. Harmonising a lexical database
with a corpus-based grammar. In Souter and
Atwell, editors, Corpus-based Computational Lin-
guistics, pages 181-193. Amsterdam: Rodopi.
[59] Clive Souter. 1993. Towards a standard format for
parsed corpora. In Jan Aarts, Pieter de Haan, and
Nelleke Oostdijk, editors, English Language Corpora:
design, analysis and exploitation; Proceedings of the
13th ICAME conference, pages 197-214. Amsterdam:
Rodopi.
</reference>
<page confidence="0.9884">
19
</page>
<reference confidence="0.995681333333333">
[60] Clive Souter and Eric Steven Atwell. 1994. Us-
ing Parsed Corpora: A review of current practice In
Nelleke Oostdijk and Pieter de Haan (eds), Corpus-
based Research Into Language, pp143-158. Amster-
,.dam, Rodopi.
[61] C. Sperberg-McQueen and L. Burnard. 1990.
Guidelines for the encoding and interchange of
machine-readable texts, TEI I)1, Technical report,
Universities of Chicago and Oxford.
[62] Jan Svartvik (ed). 1990. The London-Lund Corpus
of Spoken English: Description and Research. Lund
University Press, Lund, Sweden.
[63] L.J. Taylor and G. Knowles. 1988. Manual of In-
formation to Accompany the SEC Corpus. Technical
Report, Unit for Computer Research on the English
Language,University of Lancaster, UK.
[6 1] Ni Yibin 1993. The ICE Tagset - A Complete List
of Tags used by the Tag-Selector for the Reference
of Tag-Selectors and Researchers. Technical Report,
Department of English, University College London,
1J K .
</reference>
<page confidence="0.997988">
20
</page>
</variant>
</algorithm>
</algorithms>